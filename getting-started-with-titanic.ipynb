{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "explicit-hepatitis",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-07-05T13:00:18.959056Z",
     "iopub.status.busy": "2021-07-05T13:00:18.958023Z",
     "iopub.status.idle": "2021-07-05T13:00:18.964980Z",
     "shell.execute_reply": "2021-07-05T13:00:18.964240Z",
     "shell.execute_reply.started": "2021-07-05T12:57:49.437215Z"
    },
    "papermill": {
     "duration": 0.033815,
     "end_time": "2021-07-05T13:00:18.965170",
     "exception": false,
     "start_time": "2021-07-05T13:00:18.931355",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/titanic/train.csv\n",
      "/kaggle/input/titanic/test.csv\n",
      "/kaggle/input/titanic/gender_submission.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "sudden-proxy",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-05T13:00:18.998075Z",
     "iopub.status.busy": "2021-07-05T13:00:18.997303Z",
     "iopub.status.idle": "2021-07-05T13:00:19.047617Z",
     "shell.execute_reply": "2021-07-05T13:00:19.047043Z",
     "shell.execute_reply.started": "2021-07-05T12:57:49.453425Z"
    },
    "papermill": {
     "duration": 0.06871,
     "end_time": "2021-07-05T13:00:19.047812",
     "exception": false,
     "start_time": "2021-07-05T13:00:18.979102",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv(\"/kaggle/input/titanic/train.csv\")\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "raised-benjamin",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-05T13:00:19.080881Z",
     "iopub.status.busy": "2021-07-05T13:00:19.080046Z",
     "iopub.status.idle": "2021-07-05T13:00:19.114407Z",
     "shell.execute_reply": "2021-07-05T13:00:19.113266Z",
     "shell.execute_reply.started": "2021-07-05T12:57:49.502633Z"
    },
    "papermill": {
     "duration": 0.053565,
     "end_time": "2021-07-05T13:00:19.114640",
     "exception": false,
     "start_time": "2021-07-05T13:00:19.061075",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   PassengerId  Pclass                                          Name     Sex  \\\n",
      "0          892       3                              Kelly, Mr. James       1   \n",
      "1          893       3              Wilkes, Mrs. James (Ellen Needs)  female   \n",
      "2          894       2                     Myles, Mr. Thomas Francis       1   \n",
      "3          895       3                              Wirz, Mr. Albert       1   \n",
      "4          896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female   \n",
      "\n",
      "    Age  SibSp  Parch   Ticket     Fare Cabin Embarked  \n",
      "0  34.5      0      0   330911   7.8292   NaN        Q  \n",
      "1  47.0      1      0   363272   7.0000   NaN        S  \n",
      "2  62.0      0      0   240276   9.6875   NaN        Q  \n",
      "3  27.0      0      0   315154   8.6625   NaN        S  \n",
      "4  22.0      1      1  3101298  12.2875   NaN        S  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/pandas/core/indexing.py:1720: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value, pi)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['Q', 'S', 'C'], dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = pd.read_csv(\"/kaggle/input/titanic/test.csv\")\n",
    "test_data.head()\n",
    "think3=test_data.head()\n",
    "think3.loc[think3.Sex=='male','Sex']=1\n",
    "print(think3)\n",
    "test_data.Embarked.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "injured-retail",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-05T13:00:19.148251Z",
     "iopub.status.busy": "2021-07-05T13:00:19.147044Z",
     "iopub.status.idle": "2021-07-05T13:00:19.155915Z",
     "shell.execute_reply": "2021-07-05T13:00:19.155296Z",
     "shell.execute_reply.started": "2021-07-05T12:57:49.532517Z"
    },
    "papermill": {
     "duration": 0.027254,
     "end_time": "2021-07-05T13:00:19.156077",
     "exception": false,
     "start_time": "2021-07-05T13:00:19.128823",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29.69911764705882"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.Age.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "isolated-dispute",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-05T13:00:19.212327Z",
     "iopub.status.busy": "2021-07-05T13:00:19.201186Z",
     "iopub.status.idle": "2021-07-05T13:00:19.223496Z",
     "shell.execute_reply": "2021-07-05T13:00:19.224353Z",
     "shell.execute_reply.started": "2021-07-05T12:57:49.542633Z"
    },
    "papermill": {
     "duration": 0.051602,
     "end_time": "2021-07-05T13:00:19.224665",
     "exception": false,
     "start_time": "2021-07-05T13:00:19.173063",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PassengerId      0\n",
      "Survived         0\n",
      "Pclass           0\n",
      "Name             0\n",
      "Sex              0\n",
      "Age            177\n",
      "SibSp            0\n",
      "Parch            0\n",
      "Ticket           0\n",
      "Fare             0\n",
      "Cabin          687\n",
      "Embarked         2\n",
      "dtype: int64\n",
      "177\n",
      "train data mean is: 29.69911764705882\n",
      "     PassengerId  Survived  Pclass  \\\n",
      "0              1         0       3   \n",
      "1              2         1       1   \n",
      "2              3         1       3   \n",
      "3              4         1       1   \n",
      "4              5         0       3   \n",
      "..           ...       ...     ...   \n",
      "886          887         0       2   \n",
      "887          888         1       1   \n",
      "888          889         0       3   \n",
      "889          890         1       1   \n",
      "890          891         0       3   \n",
      "\n",
      "                                                  Name     Sex        Age  \\\n",
      "0                              Braund, Mr. Owen Harris    male  22.000000   \n",
      "1    Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.000000   \n",
      "2                               Heikkinen, Miss. Laina  female  26.000000   \n",
      "3         Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.000000   \n",
      "4                             Allen, Mr. William Henry    male  35.000000   \n",
      "..                                                 ...     ...        ...   \n",
      "886                              Montvila, Rev. Juozas    male  27.000000   \n",
      "887                       Graham, Miss. Margaret Edith  female  19.000000   \n",
      "888           Johnston, Miss. Catherine Helen \"Carrie\"  female  29.699118   \n",
      "889                              Behr, Mr. Karl Howell    male  26.000000   \n",
      "890                                Dooley, Mr. Patrick    male  32.000000   \n",
      "\n",
      "     SibSp  Parch            Ticket     Fare Cabin Embarked  \n",
      "0        1      0         A/5 21171   7.2500   NaN        S  \n",
      "1        1      0          PC 17599  71.2833   C85        C  \n",
      "2        0      0  STON/O2. 3101282   7.9250   NaN        S  \n",
      "3        1      0            113803  53.1000  C123        S  \n",
      "4        0      0            373450   8.0500   NaN        S  \n",
      "..     ...    ...               ...      ...   ...      ...  \n",
      "886      0      0            211536  13.0000   NaN        S  \n",
      "887      0      0            112053  30.0000   B42        S  \n",
      "888      1      2        W./C. 6607  23.4500   NaN        S  \n",
      "889      0      0            111369  30.0000  C148        C  \n",
      "890      0      0            370376   7.7500   NaN        Q  \n",
      "\n",
      "[891 rows x 12 columns]\n",
      "PassengerId      0\n",
      "Survived         0\n",
      "Pclass           0\n",
      "Name             0\n",
      "Sex              0\n",
      "Age              0\n",
      "SibSp            0\n",
      "Parch            0\n",
      "Ticket           0\n",
      "Fare             0\n",
      "Cabin          687\n",
      "Embarked         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(train_data.isnull().sum())\n",
    "print(train_data.Age.isnull().sum())\n",
    "print(\"train data mean is:\",(train_data.Age.mean())/1)\n",
    "train_data.loc[train_data.Age.isnull(),'Age']=train_data.Age.mean() #Age 결측 평균채우기\n",
    "print(train_data)\n",
    "train_data.loc[train_data.Embarked.isnull(),'Embarked']='S' #Embarked 결측 최빈값 채우기\n",
    "print(train_data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "developmental-gregory",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-05T13:00:19.268793Z",
     "iopub.status.busy": "2021-07-05T13:00:19.268047Z",
     "iopub.status.idle": "2021-07-05T13:00:19.272548Z",
     "shell.execute_reply": "2021-07-05T13:00:19.271942Z",
     "shell.execute_reply.started": "2021-07-05T12:57:49.571668Z"
    },
    "papermill": {
     "duration": 0.032659,
     "end_time": "2021-07-05T13:00:19.272709",
     "exception": false,
     "start_time": "2021-07-05T13:00:19.240050",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2, 1], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.loc[train_data.Sex=='female','Sex']=1\n",
    "train_data.loc[train_data.Sex=='male','Sex']=0\n",
    "train_data.loc[train_data.Embarked=='S','Embarked']=0\n",
    "train_data.loc[train_data.Embarked=='Q','Embarked']=1\n",
    "train_data.loc[train_data.Embarked=='C','Embarked']=2\n",
    "train_data #text data인 Sex, Embarked 를 측정 가능한 숫자로 바꿈.\n",
    "train_data.Embarked.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "helpful-surgery",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-05T13:00:19.310166Z",
     "iopub.status.busy": "2021-07-05T13:00:19.309435Z",
     "iopub.status.idle": "2021-07-05T13:00:19.416306Z",
     "shell.execute_reply": "2021-07-05T13:00:19.416896Z",
     "shell.execute_reply.started": "2021-07-05T12:57:49.587389Z"
    },
    "papermill": {
     "duration": 0.128973,
     "end_time": "2021-07-05T13:00:19.417097",
     "exception": false,
     "start_time": "2021-07-05T13:00:19.288124",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 3, 0, 22.0, 0, 0], [2, 1, 1, 38.0, 0, 2], [3, 3, 1, 26.0, 0, 0], [4, 1, 1, 35.0, 0, 0], [5, 3, 0, 35.0, 0, 0], [6, 3, 0, 29.69911764705882, 0, 1], [7, 1, 0, 54.0, 0, 0], [8, 3, 0, 2.0, 1, 0], [9, 3, 1, 27.0, 2, 0], [10, 2, 1, 14.0, 0, 2], [11, 3, 1, 4.0, 1, 0], [12, 1, 1, 58.0, 0, 0], [13, 3, 0, 20.0, 0, 0], [14, 3, 0, 39.0, 5, 0], [15, 3, 1, 14.0, 0, 0], [16, 2, 1, 55.0, 0, 0], [17, 3, 0, 2.0, 1, 1], [18, 2, 0, 29.69911764705882, 0, 0], [19, 3, 1, 31.0, 0, 0], [20, 3, 1, 29.69911764705882, 0, 2], [21, 2, 0, 35.0, 0, 0], [22, 2, 0, 34.0, 0, 0], [23, 3, 1, 15.0, 0, 1], [24, 1, 0, 28.0, 0, 0], [25, 3, 1, 8.0, 1, 0], [26, 3, 1, 38.0, 5, 0], [27, 3, 0, 29.69911764705882, 0, 2], [28, 1, 0, 19.0, 2, 0], [29, 3, 1, 29.69911764705882, 0, 1], [30, 3, 0, 29.69911764705882, 0, 0], [31, 1, 0, 40.0, 0, 2], [32, 1, 1, 29.69911764705882, 0, 2], [33, 3, 1, 29.69911764705882, 0, 1], [34, 2, 0, 66.0, 0, 0], [35, 1, 0, 28.0, 0, 2], [36, 1, 0, 42.0, 0, 0], [37, 3, 0, 29.69911764705882, 0, 2], [38, 3, 0, 21.0, 0, 0], [39, 3, 1, 18.0, 0, 0], [40, 3, 1, 14.0, 0, 2], [41, 3, 1, 40.0, 0, 0], [42, 2, 1, 27.0, 0, 0], [43, 3, 0, 29.69911764705882, 0, 2], [44, 2, 1, 3.0, 2, 2], [45, 3, 1, 19.0, 0, 1], [46, 3, 0, 29.69911764705882, 0, 0], [47, 3, 0, 29.69911764705882, 0, 1], [48, 3, 1, 29.69911764705882, 0, 1], [49, 3, 0, 29.69911764705882, 0, 2], [50, 3, 1, 18.0, 0, 0], [51, 3, 0, 7.0, 1, 0], [52, 3, 0, 21.0, 0, 0], [53, 1, 1, 49.0, 0, 2], [54, 2, 1, 29.0, 0, 0], [55, 1, 0, 65.0, 1, 2], [56, 1, 0, 29.69911764705882, 0, 0], [57, 2, 1, 21.0, 0, 0], [58, 3, 0, 28.5, 0, 2], [59, 2, 1, 5.0, 2, 0], [60, 3, 0, 11.0, 2, 0], [61, 3, 0, 22.0, 0, 2], [62, 1, 1, 38.0, 0, 0], [63, 1, 0, 45.0, 0, 0], [64, 3, 0, 4.0, 2, 0], [65, 1, 0, 29.69911764705882, 0, 2], [66, 3, 0, 29.69911764705882, 1, 2], [67, 2, 1, 29.0, 0, 0], [68, 3, 0, 19.0, 0, 0], [69, 3, 1, 17.0, 2, 0], [70, 3, 0, 26.0, 0, 0], [71, 2, 0, 32.0, 0, 0], [72, 3, 1, 16.0, 2, 0], [73, 2, 0, 21.0, 0, 0], [74, 3, 0, 26.0, 0, 2], [75, 3, 0, 32.0, 0, 0], [76, 3, 0, 25.0, 0, 0], [77, 3, 0, 29.69911764705882, 0, 0], [78, 3, 0, 29.69911764705882, 0, 0], [79, 2, 0, 0.83, 2, 0], [80, 3, 1, 30.0, 0, 0], [81, 3, 0, 22.0, 0, 0], [82, 3, 0, 29.0, 0, 0], [83, 3, 1, 29.69911764705882, 0, 1], [84, 1, 0, 28.0, 0, 0], [85, 2, 1, 17.0, 0, 0], [86, 3, 1, 33.0, 0, 0], [87, 3, 0, 16.0, 3, 0], [88, 3, 0, 29.69911764705882, 0, 0], [89, 1, 1, 23.0, 2, 0], [90, 3, 0, 24.0, 0, 0], [91, 3, 0, 29.0, 0, 0], [92, 3, 0, 20.0, 0, 0], [93, 1, 0, 46.0, 0, 0], [94, 3, 0, 26.0, 2, 0], [95, 3, 0, 59.0, 0, 0], [96, 3, 0, 29.69911764705882, 0, 0], [97, 1, 0, 71.0, 0, 2], [98, 1, 0, 23.0, 1, 2], [99, 2, 1, 34.0, 1, 0], [100, 2, 0, 34.0, 0, 0], [101, 3, 1, 28.0, 0, 0], [102, 3, 0, 29.69911764705882, 0, 0], [103, 1, 0, 21.0, 1, 0], [104, 3, 0, 33.0, 0, 0], [105, 3, 0, 37.0, 0, 0], [106, 3, 0, 28.0, 0, 0], [107, 3, 1, 21.0, 0, 0], [108, 3, 0, 29.69911764705882, 0, 0], [109, 3, 0, 38.0, 0, 0], [110, 3, 1, 29.69911764705882, 0, 1], [111, 1, 0, 47.0, 0, 0], [112, 3, 1, 14.5, 0, 2], [113, 3, 0, 22.0, 0, 0], [114, 3, 1, 20.0, 0, 0], [115, 3, 1, 17.0, 0, 2], [116, 3, 0, 21.0, 0, 0], [117, 3, 0, 70.5, 0, 1], [118, 2, 0, 29.0, 0, 0], [119, 1, 0, 24.0, 1, 2], [120, 3, 1, 2.0, 2, 0], [121, 2, 0, 21.0, 0, 0], [122, 3, 0, 29.69911764705882, 0, 0], [123, 2, 0, 32.5, 0, 2], [124, 2, 1, 32.5, 0, 0], [125, 1, 0, 54.0, 1, 0], [126, 3, 0, 12.0, 0, 2], [127, 3, 0, 29.69911764705882, 0, 1], [128, 3, 0, 24.0, 0, 0], [129, 3, 1, 29.69911764705882, 1, 2], [130, 3, 0, 45.0, 0, 0], [131, 3, 0, 33.0, 0, 2], [132, 3, 0, 20.0, 0, 0], [133, 3, 1, 47.0, 0, 0], [134, 2, 1, 29.0, 0, 0], [135, 2, 0, 25.0, 0, 0], [136, 2, 0, 23.0, 0, 2], [137, 1, 1, 19.0, 2, 0], [138, 1, 0, 37.0, 0, 0], [139, 3, 0, 16.0, 0, 0], [140, 1, 0, 24.0, 0, 2], [141, 3, 1, 29.69911764705882, 2, 2], [142, 3, 1, 22.0, 0, 0], [143, 3, 1, 24.0, 0, 0], [144, 3, 0, 19.0, 0, 1], [145, 2, 0, 18.0, 0, 0], [146, 2, 0, 19.0, 1, 0], [147, 3, 0, 27.0, 0, 0], [148, 3, 1, 9.0, 2, 0], [149, 2, 0, 36.5, 2, 0], [150, 2, 0, 42.0, 0, 0], [151, 2, 0, 51.0, 0, 0], [152, 1, 1, 22.0, 0, 0], [153, 3, 0, 55.5, 0, 0], [154, 3, 0, 40.5, 2, 0], [155, 3, 0, 29.69911764705882, 0, 0], [156, 1, 0, 51.0, 1, 2], [157, 3, 1, 16.0, 0, 1], [158, 3, 0, 30.0, 0, 0], [159, 3, 0, 29.69911764705882, 0, 0], [160, 3, 0, 29.69911764705882, 2, 0], [161, 3, 0, 44.0, 1, 0], [162, 2, 1, 40.0, 0, 0], [163, 3, 0, 26.0, 0, 0], [164, 3, 0, 17.0, 0, 0], [165, 3, 0, 1.0, 1, 0], [166, 3, 0, 9.0, 2, 0], [167, 1, 1, 29.69911764705882, 1, 0], [168, 3, 1, 45.0, 4, 0], [169, 1, 0, 29.69911764705882, 0, 0], [170, 3, 0, 28.0, 0, 0], [171, 1, 0, 61.0, 0, 0], [172, 3, 0, 4.0, 1, 1], [173, 3, 1, 1.0, 1, 0], [174, 3, 0, 21.0, 0, 0], [175, 1, 0, 56.0, 0, 2], [176, 3, 0, 18.0, 1, 0], [177, 3, 0, 29.69911764705882, 1, 0], [178, 1, 1, 50.0, 0, 2], [179, 2, 0, 30.0, 0, 0], [180, 3, 0, 36.0, 0, 0], [181, 3, 1, 29.69911764705882, 2, 0], [182, 2, 0, 29.69911764705882, 0, 2], [183, 3, 0, 9.0, 2, 0], [184, 2, 0, 1.0, 1, 0], [185, 3, 1, 4.0, 2, 0], [186, 1, 0, 29.69911764705882, 0, 0], [187, 3, 1, 29.69911764705882, 0, 1], [188, 1, 0, 45.0, 0, 0], [189, 3, 0, 40.0, 1, 1], [190, 3, 0, 36.0, 0, 0], [191, 2, 1, 32.0, 0, 0], [192, 2, 0, 19.0, 0, 0], [193, 3, 1, 19.0, 0, 0], [194, 2, 0, 3.0, 1, 0], [195, 1, 1, 44.0, 0, 2], [196, 1, 1, 58.0, 0, 2], [197, 3, 0, 29.69911764705882, 0, 1], [198, 3, 0, 42.0, 1, 0], [199, 3, 1, 29.69911764705882, 0, 1], [200, 2, 1, 24.0, 0, 0], [201, 3, 0, 28.0, 0, 0], [202, 3, 0, 29.69911764705882, 2, 0], [203, 3, 0, 34.0, 0, 0], [204, 3, 0, 45.5, 0, 2], [205, 3, 0, 18.0, 0, 0], [206, 3, 1, 2.0, 1, 0], [207, 3, 0, 32.0, 0, 0], [208, 3, 0, 26.0, 0, 2], [209, 3, 1, 16.0, 0, 1], [210, 1, 0, 40.0, 0, 2], [211, 3, 0, 24.0, 0, 0], [212, 2, 1, 35.0, 0, 0], [213, 3, 0, 22.0, 0, 0], [214, 2, 0, 30.0, 0, 0], [215, 3, 0, 29.69911764705882, 0, 1], [216, 1, 1, 31.0, 0, 2], [217, 3, 1, 27.0, 0, 0], [218, 2, 0, 42.0, 0, 0], [219, 1, 1, 32.0, 0, 2], [220, 2, 0, 30.0, 0, 0], [221, 3, 0, 16.0, 0, 0], [222, 2, 0, 27.0, 0, 0], [223, 3, 0, 51.0, 0, 0], [224, 3, 0, 29.69911764705882, 0, 0], [225, 1, 0, 38.0, 0, 0], [226, 3, 0, 22.0, 0, 0], [227, 2, 0, 19.0, 0, 0], [228, 3, 0, 20.5, 0, 0], [229, 2, 0, 18.0, 0, 0], [230, 3, 1, 29.69911764705882, 1, 0], [231, 1, 1, 35.0, 0, 0], [232, 3, 0, 29.0, 0, 0], [233, 2, 0, 59.0, 0, 0], [234, 3, 1, 5.0, 2, 0], [235, 2, 0, 24.0, 0, 0], [236, 3, 1, 29.69911764705882, 0, 0], [237, 2, 0, 44.0, 0, 0], [238, 2, 1, 8.0, 2, 0], [239, 2, 0, 19.0, 0, 0], [240, 2, 0, 33.0, 0, 0], [241, 3, 1, 29.69911764705882, 0, 2], [242, 3, 1, 29.69911764705882, 0, 1], [243, 2, 0, 29.0, 0, 0], [244, 3, 0, 22.0, 0, 0], [245, 3, 0, 30.0, 0, 2], [246, 1, 0, 44.0, 0, 1], [247, 3, 1, 25.0, 0, 0], [248, 2, 1, 24.0, 2, 0], [249, 1, 0, 37.0, 1, 0], [250, 2, 0, 54.0, 0, 0], [251, 3, 0, 29.69911764705882, 0, 0], [252, 3, 1, 29.0, 1, 0], [253, 1, 0, 62.0, 0, 0], [254, 3, 0, 30.0, 0, 0], [255, 3, 1, 41.0, 2, 0], [256, 3, 1, 29.0, 2, 2], [257, 1, 1, 29.69911764705882, 0, 2], [258, 1, 1, 30.0, 0, 0], [259, 1, 1, 35.0, 0, 2], [260, 2, 1, 50.0, 1, 0], [261, 3, 0, 29.69911764705882, 0, 1], [262, 3, 0, 3.0, 2, 0], [263, 1, 0, 52.0, 1, 0], [264, 1, 0, 40.0, 0, 0], [265, 3, 1, 29.69911764705882, 0, 1], [266, 2, 0, 36.0, 0, 0], [267, 3, 0, 16.0, 1, 0], [268, 3, 0, 25.0, 0, 0], [269, 1, 1, 58.0, 1, 0], [270, 1, 1, 35.0, 0, 0], [271, 1, 0, 29.69911764705882, 0, 0], [272, 3, 0, 25.0, 0, 0], [273, 2, 1, 41.0, 1, 0], [274, 1, 0, 37.0, 1, 2], [275, 3, 1, 29.69911764705882, 0, 1], [276, 1, 1, 63.0, 0, 0], [277, 3, 1, 45.0, 0, 0], [278, 2, 0, 29.69911764705882, 0, 0], [279, 3, 0, 7.0, 1, 1], [280, 3, 1, 35.0, 1, 0], [281, 3, 0, 65.0, 0, 1], [282, 3, 0, 28.0, 0, 0], [283, 3, 0, 16.0, 0, 0], [284, 3, 0, 19.0, 0, 0], [285, 1, 0, 29.69911764705882, 0, 0], [286, 3, 0, 33.0, 0, 2], [287, 3, 0, 30.0, 0, 0], [288, 3, 0, 22.0, 0, 0], [289, 2, 0, 42.0, 0, 0], [290, 3, 1, 22.0, 0, 1], [291, 1, 1, 26.0, 0, 0], [292, 1, 1, 19.0, 0, 2], [293, 2, 0, 36.0, 0, 2], [294, 3, 1, 24.0, 0, 0], [295, 3, 0, 24.0, 0, 0], [296, 1, 0, 29.69911764705882, 0, 2], [297, 3, 0, 23.5, 0, 2], [298, 1, 1, 2.0, 2, 0], [299, 1, 0, 29.69911764705882, 0, 0], [300, 1, 1, 50.0, 1, 2], [301, 3, 1, 29.69911764705882, 0, 1], [302, 3, 0, 29.69911764705882, 0, 1], [303, 3, 0, 19.0, 0, 0], [304, 2, 1, 29.69911764705882, 0, 1], [305, 3, 0, 29.69911764705882, 0, 0], [306, 1, 0, 0.92, 2, 0], [307, 1, 1, 29.69911764705882, 0, 2], [308, 1, 1, 17.0, 0, 2], [309, 2, 0, 30.0, 0, 2], [310, 1, 1, 30.0, 0, 2], [311, 1, 1, 24.0, 0, 2], [312, 1, 1, 18.0, 2, 2], [313, 2, 1, 26.0, 1, 0], [314, 3, 0, 28.0, 0, 0], [315, 2, 0, 43.0, 1, 0], [316, 3, 1, 26.0, 0, 0], [317, 2, 1, 24.0, 0, 0], [318, 2, 0, 54.0, 0, 0], [319, 1, 1, 31.0, 2, 0], [320, 1, 1, 40.0, 1, 2], [321, 3, 0, 22.0, 0, 0], [322, 3, 0, 27.0, 0, 0], [323, 2, 1, 30.0, 0, 1], [324, 2, 1, 22.0, 1, 0], [325, 3, 0, 29.69911764705882, 2, 0], [326, 1, 1, 36.0, 0, 2], [327, 3, 0, 61.0, 0, 0], [328, 2, 1, 36.0, 0, 0], [329, 3, 1, 31.0, 1, 0], [330, 1, 1, 16.0, 1, 2], [331, 3, 1, 29.69911764705882, 0, 1], [332, 1, 0, 45.5, 0, 0], [333, 1, 0, 38.0, 1, 0], [334, 3, 0, 16.0, 0, 0], [335, 1, 1, 29.69911764705882, 0, 0], [336, 3, 0, 29.69911764705882, 0, 0], [337, 1, 0, 29.0, 0, 0], [338, 1, 1, 41.0, 0, 2], [339, 3, 0, 45.0, 0, 0], [340, 1, 0, 45.0, 0, 0], [341, 2, 0, 2.0, 1, 0], [342, 1, 1, 24.0, 2, 0], [343, 2, 0, 28.0, 0, 0], [344, 2, 0, 25.0, 0, 0], [345, 2, 0, 36.0, 0, 0], [346, 2, 1, 24.0, 0, 0], [347, 2, 1, 40.0, 0, 0], [348, 3, 1, 29.69911764705882, 0, 0], [349, 3, 0, 3.0, 1, 0], [350, 3, 0, 42.0, 0, 0], [351, 3, 0, 23.0, 0, 0], [352, 1, 0, 29.69911764705882, 0, 0], [353, 3, 0, 15.0, 1, 2], [354, 3, 0, 25.0, 0, 0], [355, 3, 0, 29.69911764705882, 0, 2], [356, 3, 0, 28.0, 0, 0], [357, 1, 1, 22.0, 1, 0], [358, 2, 1, 38.0, 0, 0], [359, 3, 1, 29.69911764705882, 0, 1], [360, 3, 1, 29.69911764705882, 0, 1], [361, 3, 0, 40.0, 4, 0], [362, 2, 0, 29.0, 0, 2], [363, 3, 1, 45.0, 1, 2], [364, 3, 0, 35.0, 0, 0], [365, 3, 0, 29.69911764705882, 0, 1], [366, 3, 0, 30.0, 0, 0], [367, 1, 1, 60.0, 0, 2], [368, 3, 1, 29.69911764705882, 0, 2], [369, 3, 1, 29.69911764705882, 0, 1], [370, 1, 1, 24.0, 0, 2], [371, 1, 0, 25.0, 0, 2], [372, 3, 0, 18.0, 0, 0], [373, 3, 0, 19.0, 0, 0], [374, 1, 0, 22.0, 0, 2], [375, 3, 1, 3.0, 1, 0], [376, 1, 1, 29.69911764705882, 0, 2], [377, 3, 1, 22.0, 0, 0], [378, 1, 0, 27.0, 2, 2], [379, 3, 0, 20.0, 0, 2], [380, 3, 0, 19.0, 0, 0], [381, 1, 1, 42.0, 0, 2], [382, 3, 1, 1.0, 2, 2], [383, 3, 0, 32.0, 0, 0], [384, 1, 1, 35.0, 0, 0], [385, 3, 0, 29.69911764705882, 0, 0], [386, 2, 0, 18.0, 0, 0], [387, 3, 0, 1.0, 2, 0], [388, 2, 1, 36.0, 0, 0], [389, 3, 0, 29.69911764705882, 0, 1], [390, 2, 1, 17.0, 0, 2], [391, 1, 0, 36.0, 2, 0], [392, 3, 0, 21.0, 0, 0], [393, 3, 0, 28.0, 0, 0], [394, 1, 1, 23.0, 0, 2], [395, 3, 1, 24.0, 2, 0], [396, 3, 0, 22.0, 0, 0], [397, 3, 1, 31.0, 0, 0], [398, 2, 0, 46.0, 0, 0], [399, 2, 0, 23.0, 0, 0], [400, 2, 1, 28.0, 0, 0], [401, 3, 0, 39.0, 0, 0], [402, 3, 0, 26.0, 0, 0], [403, 3, 1, 21.0, 0, 0], [404, 3, 0, 28.0, 0, 0], [405, 3, 1, 20.0, 0, 0], [406, 2, 0, 34.0, 0, 0], [407, 3, 0, 51.0, 0, 0], [408, 2, 0, 3.0, 1, 0], [409, 3, 0, 21.0, 0, 0], [410, 3, 1, 29.69911764705882, 1, 0], [411, 3, 0, 29.69911764705882, 0, 0], [412, 3, 0, 29.69911764705882, 0, 1], [413, 1, 1, 33.0, 0, 1], [414, 2, 0, 29.69911764705882, 0, 0], [415, 3, 0, 44.0, 0, 0], [416, 3, 1, 29.69911764705882, 0, 0], [417, 2, 1, 34.0, 1, 0], [418, 2, 1, 18.0, 2, 0], [419, 2, 0, 30.0, 0, 0], [420, 3, 1, 10.0, 2, 0], [421, 3, 0, 29.69911764705882, 0, 2], [422, 3, 0, 21.0, 0, 1], [423, 3, 0, 29.0, 0, 0], [424, 3, 1, 28.0, 1, 0], [425, 3, 0, 18.0, 1, 0], [426, 3, 0, 29.69911764705882, 0, 0], [427, 2, 1, 28.0, 0, 0], [428, 2, 1, 19.0, 0, 0], [429, 3, 0, 29.69911764705882, 0, 1], [430, 3, 0, 32.0, 0, 0], [431, 1, 0, 28.0, 0, 0], [432, 3, 1, 29.69911764705882, 0, 0], [433, 2, 1, 42.0, 0, 0], [434, 3, 0, 17.0, 0, 0], [435, 1, 0, 50.0, 0, 0], [436, 1, 1, 14.0, 2, 0], [437, 3, 1, 21.0, 2, 0], [438, 2, 1, 24.0, 3, 0], [439, 1, 0, 64.0, 4, 0], [440, 2, 0, 31.0, 0, 0], [441, 2, 1, 45.0, 1, 0], [442, 3, 0, 20.0, 0, 0], [443, 3, 0, 25.0, 0, 0], [444, 2, 1, 28.0, 0, 0], [445, 3, 0, 29.69911764705882, 0, 0], [446, 1, 0, 4.0, 2, 0], [447, 2, 1, 13.0, 1, 0], [448, 1, 0, 34.0, 0, 0], [449, 3, 1, 5.0, 1, 2], [450, 1, 0, 52.0, 0, 0], [451, 2, 0, 36.0, 2, 0], [452, 3, 0, 29.69911764705882, 0, 0], [453, 1, 0, 30.0, 0, 2], [454, 1, 0, 49.0, 0, 2], [455, 3, 0, 29.69911764705882, 0, 0], [456, 3, 0, 29.0, 0, 2], [457, 1, 0, 65.0, 0, 0], [458, 1, 1, 29.69911764705882, 0, 0], [459, 2, 1, 50.0, 0, 0], [460, 3, 0, 29.69911764705882, 0, 1], [461, 1, 0, 48.0, 0, 0], [462, 3, 0, 34.0, 0, 0], [463, 1, 0, 47.0, 0, 0], [464, 2, 0, 48.0, 0, 0], [465, 3, 0, 29.69911764705882, 0, 0], [466, 3, 0, 38.0, 0, 0], [467, 2, 0, 29.69911764705882, 0, 0], [468, 1, 0, 56.0, 0, 0], [469, 3, 0, 29.69911764705882, 0, 1], [470, 3, 1, 0.75, 1, 2], [471, 3, 0, 29.69911764705882, 0, 0], [472, 3, 0, 38.0, 0, 0], [473, 2, 1, 33.0, 2, 0], [474, 2, 1, 23.0, 0, 2], [475, 3, 1, 22.0, 0, 0], [476, 1, 0, 29.69911764705882, 0, 0], [477, 2, 0, 34.0, 0, 0], [478, 3, 0, 29.0, 0, 0], [479, 3, 0, 22.0, 0, 0], [480, 3, 1, 2.0, 1, 0], [481, 3, 0, 9.0, 2, 0], [482, 2, 0, 29.69911764705882, 0, 0], [483, 3, 0, 50.0, 0, 0], [484, 3, 1, 63.0, 0, 0], [485, 1, 0, 25.0, 0, 2], [486, 3, 1, 29.69911764705882, 1, 0], [487, 1, 1, 35.0, 0, 0], [488, 1, 0, 58.0, 0, 2], [489, 3, 0, 30.0, 0, 0], [490, 3, 0, 9.0, 1, 0], [491, 3, 0, 29.69911764705882, 0, 0], [492, 3, 0, 21.0, 0, 0], [493, 1, 0, 55.0, 0, 0], [494, 1, 0, 71.0, 0, 2], [495, 3, 0, 21.0, 0, 0], [496, 3, 0, 29.69911764705882, 0, 2], [497, 1, 1, 54.0, 0, 2], [498, 3, 0, 29.69911764705882, 0, 0], [499, 1, 1, 25.0, 2, 0], [500, 3, 0, 24.0, 0, 0], [501, 3, 0, 17.0, 0, 0], [502, 3, 1, 21.0, 0, 1], [503, 3, 1, 29.69911764705882, 0, 1], [504, 3, 1, 37.0, 0, 0], [505, 1, 1, 16.0, 0, 0], [506, 1, 0, 18.0, 0, 2], [507, 2, 1, 33.0, 2, 0], [508, 1, 0, 29.69911764705882, 0, 0], [509, 3, 0, 28.0, 0, 0], [510, 3, 0, 26.0, 0, 0], [511, 3, 0, 29.0, 0, 1], [512, 3, 0, 29.69911764705882, 0, 0], [513, 1, 0, 36.0, 0, 0], [514, 1, 1, 54.0, 0, 2], [515, 3, 0, 24.0, 0, 0], [516, 1, 0, 47.0, 0, 0], [517, 2, 1, 34.0, 0, 0], [518, 3, 0, 29.69911764705882, 0, 1], [519, 2, 1, 36.0, 0, 0], [520, 3, 0, 32.0, 0, 0], [521, 1, 1, 30.0, 0, 0], [522, 3, 0, 22.0, 0, 0], [523, 3, 0, 29.69911764705882, 0, 2], [524, 1, 1, 44.0, 1, 2], [525, 3, 0, 29.69911764705882, 0, 2], [526, 3, 0, 40.5, 0, 1], [527, 2, 1, 50.0, 0, 0], [528, 1, 0, 29.69911764705882, 0, 0], [529, 3, 0, 39.0, 0, 0], [530, 2, 0, 23.0, 1, 0], [531, 2, 1, 2.0, 1, 0], [532, 3, 0, 29.69911764705882, 0, 2], [533, 3, 0, 17.0, 1, 2], [534, 3, 1, 29.69911764705882, 2, 2], [535, 3, 1, 30.0, 0, 0], [536, 2, 1, 7.0, 2, 0], [537, 1, 0, 45.0, 0, 0], [538, 1, 1, 30.0, 0, 2], [539, 3, 0, 29.69911764705882, 0, 0], [540, 1, 1, 22.0, 2, 2], [541, 1, 1, 36.0, 2, 0], [542, 3, 1, 9.0, 2, 0], [543, 3, 1, 11.0, 2, 0], [544, 2, 0, 32.0, 0, 0], [545, 1, 0, 50.0, 0, 2], [546, 1, 0, 64.0, 0, 0], [547, 2, 1, 19.0, 0, 0], [548, 2, 0, 29.69911764705882, 0, 2], [549, 3, 0, 33.0, 1, 0], [550, 2, 0, 8.0, 1, 0], [551, 1, 0, 17.0, 2, 2], [552, 2, 0, 27.0, 0, 0], [553, 3, 0, 29.69911764705882, 0, 1], [554, 3, 0, 22.0, 0, 2], [555, 3, 1, 22.0, 0, 0], [556, 1, 0, 62.0, 0, 0], [557, 1, 1, 48.0, 0, 2], [558, 1, 0, 29.69911764705882, 0, 2], [559, 1, 1, 39.0, 1, 0], [560, 3, 1, 36.0, 0, 0], [561, 3, 0, 29.69911764705882, 0, 1], [562, 3, 0, 40.0, 0, 0], [563, 2, 0, 28.0, 0, 0], [564, 3, 0, 29.69911764705882, 0, 0], [565, 3, 1, 29.69911764705882, 0, 0], [566, 3, 0, 24.0, 0, 0], [567, 3, 0, 19.0, 0, 0], [568, 3, 1, 29.0, 4, 0], [569, 3, 0, 29.69911764705882, 0, 2], [570, 3, 0, 32.0, 0, 0], [571, 2, 0, 62.0, 0, 0], [572, 1, 1, 53.0, 0, 0], [573, 1, 0, 36.0, 0, 0], [574, 3, 1, 29.69911764705882, 0, 1], [575, 3, 0, 16.0, 0, 0], [576, 3, 0, 19.0, 0, 0], [577, 2, 1, 34.0, 0, 0], [578, 1, 1, 39.0, 0, 0], [579, 3, 1, 29.69911764705882, 0, 2], [580, 3, 0, 32.0, 0, 0], [581, 2, 1, 25.0, 1, 0], [582, 1, 1, 39.0, 1, 2], [583, 2, 0, 54.0, 0, 0], [584, 1, 0, 36.0, 0, 2], [585, 3, 0, 29.69911764705882, 0, 2], [586, 1, 1, 18.0, 2, 0], [587, 2, 0, 47.0, 0, 0], [588, 1, 0, 60.0, 1, 2], [589, 3, 0, 22.0, 0, 0], [590, 3, 0, 29.69911764705882, 0, 0], [591, 3, 0, 35.0, 0, 0], [592, 1, 1, 52.0, 0, 2], [593, 3, 0, 47.0, 0, 0], [594, 3, 1, 29.69911764705882, 2, 1], [595, 2, 0, 37.0, 0, 0], [596, 3, 0, 36.0, 1, 0], [597, 2, 1, 29.69911764705882, 0, 0], [598, 3, 0, 49.0, 0, 0], [599, 3, 0, 29.69911764705882, 0, 2], [600, 1, 0, 49.0, 0, 2], [601, 2, 1, 24.0, 1, 0], [602, 3, 0, 29.69911764705882, 0, 0], [603, 1, 0, 29.69911764705882, 0, 0], [604, 3, 0, 44.0, 0, 0], [605, 1, 0, 35.0, 0, 2], [606, 3, 0, 36.0, 0, 0], [607, 3, 0, 30.0, 0, 0], [608, 1, 0, 27.0, 0, 0], [609, 2, 1, 22.0, 2, 2], [610, 1, 1, 40.0, 0, 0], [611, 3, 1, 39.0, 5, 0], [612, 3, 0, 29.69911764705882, 0, 0], [613, 3, 1, 29.69911764705882, 0, 1], [614, 3, 0, 29.69911764705882, 0, 1], [615, 3, 0, 35.0, 0, 0], [616, 2, 1, 24.0, 2, 0], [617, 3, 0, 34.0, 1, 0], [618, 3, 1, 26.0, 0, 0], [619, 2, 1, 4.0, 1, 0], [620, 2, 0, 26.0, 0, 0], [621, 3, 0, 27.0, 0, 2], [622, 1, 0, 42.0, 0, 0], [623, 3, 0, 20.0, 1, 2], [624, 3, 0, 21.0, 0, 0], [625, 3, 0, 21.0, 0, 0], [626, 1, 0, 61.0, 0, 0], [627, 2, 0, 57.0, 0, 1], [628, 1, 1, 21.0, 0, 0], [629, 3, 0, 26.0, 0, 0], [630, 3, 0, 29.69911764705882, 0, 1], [631, 1, 0, 80.0, 0, 0], [632, 3, 0, 51.0, 0, 0], [633, 1, 0, 32.0, 0, 2], [634, 1, 0, 29.69911764705882, 0, 0], [635, 3, 1, 9.0, 2, 0], [636, 2, 1, 28.0, 0, 0], [637, 3, 0, 32.0, 0, 0], [638, 2, 0, 31.0, 1, 0], [639, 3, 1, 41.0, 5, 0], [640, 3, 0, 29.69911764705882, 0, 0], [641, 3, 0, 20.0, 0, 0], [642, 1, 1, 24.0, 0, 2], [643, 3, 1, 2.0, 2, 0], [644, 3, 0, 29.69911764705882, 0, 0], [645, 3, 1, 0.75, 1, 2], [646, 1, 0, 48.0, 0, 2], [647, 3, 0, 19.0, 0, 0], [648, 1, 0, 56.0, 0, 2], [649, 3, 0, 29.69911764705882, 0, 0], [650, 3, 1, 23.0, 0, 0], [651, 3, 0, 29.69911764705882, 0, 0], [652, 2, 1, 18.0, 1, 0], [653, 3, 0, 21.0, 0, 0], [654, 3, 1, 29.69911764705882, 0, 1], [655, 3, 1, 18.0, 0, 1], [656, 2, 0, 24.0, 0, 0], [657, 3, 0, 29.69911764705882, 0, 0], [658, 3, 1, 32.0, 1, 1], [659, 2, 0, 23.0, 0, 0], [660, 1, 0, 58.0, 2, 2], [661, 1, 0, 50.0, 0, 0], [662, 3, 0, 40.0, 0, 2], [663, 1, 0, 47.0, 0, 0], [664, 3, 0, 36.0, 0, 0], [665, 3, 0, 20.0, 0, 0], [666, 2, 0, 32.0, 0, 0], [667, 2, 0, 25.0, 0, 0], [668, 3, 0, 29.69911764705882, 0, 0], [669, 3, 0, 43.0, 0, 0], [670, 1, 1, 29.69911764705882, 0, 0], [671, 2, 1, 40.0, 1, 0], [672, 1, 0, 31.0, 0, 0], [673, 2, 0, 70.0, 0, 0], [674, 2, 0, 31.0, 0, 0], [675, 2, 0, 29.69911764705882, 0, 0], [676, 3, 0, 18.0, 0, 0], [677, 3, 0, 24.5, 0, 0], [678, 3, 1, 18.0, 0, 0], [679, 3, 1, 43.0, 6, 0], [680, 1, 0, 36.0, 1, 2], [681, 3, 1, 29.69911764705882, 0, 1], [682, 1, 0, 27.0, 0, 2], [683, 3, 0, 20.0, 0, 0], [684, 3, 0, 14.0, 2, 0], [685, 2, 0, 60.0, 1, 0], [686, 2, 0, 25.0, 2, 2], [687, 3, 0, 14.0, 1, 0], [688, 3, 0, 19.0, 0, 0], [689, 3, 0, 18.0, 0, 0], [690, 1, 1, 15.0, 1, 0], [691, 1, 0, 31.0, 0, 0], [692, 3, 1, 4.0, 1, 2], [693, 3, 0, 29.69911764705882, 0, 0], [694, 3, 0, 25.0, 0, 2], [695, 1, 0, 60.0, 0, 0], [696, 2, 0, 52.0, 0, 0], [697, 3, 0, 44.0, 0, 0], [698, 3, 1, 29.69911764705882, 0, 1], [699, 1, 0, 49.0, 1, 2], [700, 3, 0, 42.0, 0, 0], [701, 1, 1, 18.0, 0, 2], [702, 1, 0, 35.0, 0, 0], [703, 3, 1, 18.0, 1, 2], [704, 3, 0, 25.0, 0, 1], [705, 3, 0, 26.0, 0, 0], [706, 2, 0, 39.0, 0, 0], [707, 2, 1, 45.0, 0, 0], [708, 1, 0, 42.0, 0, 0], [709, 1, 1, 22.0, 0, 0], [710, 3, 0, 29.69911764705882, 1, 2], [711, 1, 1, 24.0, 0, 2], [712, 1, 0, 29.69911764705882, 0, 0], [713, 1, 0, 48.0, 0, 0], [714, 3, 0, 29.0, 0, 0], [715, 2, 0, 52.0, 0, 0], [716, 3, 0, 19.0, 0, 0], [717, 1, 1, 38.0, 0, 2], [718, 2, 1, 27.0, 0, 0], [719, 3, 0, 29.69911764705882, 0, 1], [720, 3, 0, 33.0, 0, 0], [721, 2, 1, 6.0, 1, 0], [722, 3, 0, 17.0, 0, 0], [723, 2, 0, 34.0, 0, 0], [724, 2, 0, 50.0, 0, 0], [725, 1, 0, 27.0, 0, 0], [726, 3, 0, 20.0, 0, 0], [727, 2, 1, 30.0, 0, 0], [728, 3, 1, 29.69911764705882, 0, 1], [729, 2, 0, 25.0, 0, 0], [730, 3, 1, 25.0, 0, 0], [731, 1, 1, 29.0, 0, 0], [732, 3, 0, 11.0, 0, 2], [733, 2, 0, 29.69911764705882, 0, 0], [734, 2, 0, 23.0, 0, 0], [735, 2, 0, 23.0, 0, 0], [736, 3, 0, 28.5, 0, 0], [737, 3, 1, 48.0, 3, 0], [738, 1, 0, 35.0, 0, 2], [739, 3, 0, 29.69911764705882, 0, 0], [740, 3, 0, 29.69911764705882, 0, 0], [741, 1, 0, 29.69911764705882, 0, 0], [742, 1, 0, 36.0, 0, 0], [743, 1, 1, 21.0, 2, 2], [744, 3, 0, 24.0, 0, 0], [745, 3, 0, 31.0, 0, 0], [746, 1, 0, 70.0, 1, 0], [747, 3, 0, 16.0, 1, 0], [748, 2, 1, 30.0, 0, 0], [749, 1, 0, 19.0, 0, 0], [750, 3, 0, 31.0, 0, 1], [751, 2, 1, 4.0, 1, 0], [752, 3, 0, 6.0, 1, 0], [753, 3, 0, 33.0, 0, 0], [754, 3, 0, 23.0, 0, 0], [755, 2, 1, 48.0, 2, 0], [756, 2, 0, 0.67, 1, 0], [757, 3, 0, 28.0, 0, 0], [758, 2, 0, 18.0, 0, 0], [759, 3, 0, 34.0, 0, 0], [760, 1, 1, 33.0, 0, 0], [761, 3, 0, 29.69911764705882, 0, 0], [762, 3, 0, 41.0, 0, 0], [763, 3, 0, 20.0, 0, 2], [764, 1, 1, 36.0, 2, 0], [765, 3, 0, 16.0, 0, 0], [766, 1, 1, 51.0, 0, 0], [767, 1, 0, 29.69911764705882, 0, 2], [768, 3, 1, 30.5, 0, 1], [769, 3, 0, 29.69911764705882, 0, 1], [770, 3, 0, 32.0, 0, 0], [771, 3, 0, 24.0, 0, 0], [772, 3, 0, 48.0, 0, 0], [773, 2, 1, 57.0, 0, 0], [774, 3, 0, 29.69911764705882, 0, 2], [775, 2, 1, 54.0, 3, 0], [776, 3, 0, 18.0, 0, 0], [777, 3, 0, 29.69911764705882, 0, 1], [778, 3, 1, 5.0, 0, 0], [779, 3, 0, 29.69911764705882, 0, 1], [780, 1, 1, 43.0, 1, 0], [781, 3, 1, 13.0, 0, 2], [782, 1, 1, 17.0, 0, 0], [783, 1, 0, 29.0, 0, 0], [784, 3, 0, 29.69911764705882, 2, 0], [785, 3, 0, 25.0, 0, 0], [786, 3, 0, 25.0, 0, 0], [787, 3, 1, 18.0, 0, 0], [788, 3, 0, 8.0, 1, 1], [789, 3, 0, 1.0, 2, 0], [790, 1, 0, 46.0, 0, 2], [791, 3, 0, 29.69911764705882, 0, 1], [792, 2, 0, 16.0, 0, 0], [793, 3, 1, 29.69911764705882, 2, 0], [794, 1, 0, 29.69911764705882, 0, 2], [795, 3, 0, 25.0, 0, 0], [796, 2, 0, 39.0, 0, 0], [797, 1, 1, 49.0, 0, 0], [798, 3, 1, 31.0, 0, 0], [799, 3, 0, 30.0, 0, 2], [800, 3, 1, 30.0, 1, 0], [801, 2, 0, 34.0, 0, 0], [802, 2, 1, 31.0, 1, 0], [803, 1, 0, 11.0, 2, 0], [804, 3, 0, 0.42, 1, 2], [805, 3, 0, 27.0, 0, 0], [806, 3, 0, 31.0, 0, 0], [807, 1, 0, 39.0, 0, 0], [808, 3, 1, 18.0, 0, 0], [809, 2, 0, 39.0, 0, 0], [810, 1, 1, 33.0, 0, 0], [811, 3, 0, 26.0, 0, 0], [812, 3, 0, 39.0, 0, 0], [813, 2, 0, 35.0, 0, 0], [814, 3, 1, 6.0, 2, 0], [815, 3, 0, 30.5, 0, 0], [816, 1, 0, 29.69911764705882, 0, 0], [817, 3, 1, 23.0, 0, 0], [818, 2, 0, 31.0, 1, 2], [819, 3, 0, 43.0, 0, 0], [820, 3, 0, 10.0, 2, 0], [821, 1, 1, 52.0, 1, 0], [822, 3, 0, 27.0, 0, 0], [823, 1, 0, 38.0, 0, 0], [824, 3, 1, 27.0, 1, 0], [825, 3, 0, 2.0, 1, 0], [826, 3, 0, 29.69911764705882, 0, 1], [827, 3, 0, 29.69911764705882, 0, 0], [828, 2, 0, 1.0, 2, 2], [829, 3, 0, 29.69911764705882, 0, 1], [830, 1, 1, 62.0, 0, 0], [831, 3, 1, 15.0, 0, 2], [832, 2, 0, 0.83, 1, 0], [833, 3, 0, 29.69911764705882, 0, 2], [834, 3, 0, 23.0, 0, 0], [835, 3, 0, 18.0, 0, 0], [836, 1, 1, 39.0, 1, 2], [837, 3, 0, 21.0, 0, 0], [838, 3, 0, 29.69911764705882, 0, 0], [839, 3, 0, 32.0, 0, 0], [840, 1, 0, 29.69911764705882, 0, 2], [841, 3, 0, 20.0, 0, 0], [842, 2, 0, 16.0, 0, 0], [843, 1, 1, 30.0, 0, 2], [844, 3, 0, 34.5, 0, 2], [845, 3, 0, 17.0, 0, 0], [846, 3, 0, 42.0, 0, 0], [847, 3, 0, 29.69911764705882, 2, 0], [848, 3, 0, 35.0, 0, 2], [849, 2, 0, 28.0, 1, 0], [850, 1, 1, 29.69911764705882, 0, 2], [851, 3, 0, 4.0, 2, 0], [852, 3, 0, 74.0, 0, 0], [853, 3, 1, 9.0, 1, 2], [854, 1, 1, 16.0, 1, 0], [855, 2, 1, 44.0, 0, 0], [856, 3, 1, 18.0, 1, 0], [857, 1, 1, 45.0, 1, 0], [858, 1, 0, 51.0, 0, 0], [859, 3, 1, 24.0, 3, 2], [860, 3, 0, 29.69911764705882, 0, 2], [861, 3, 0, 41.0, 0, 0], [862, 2, 0, 21.0, 0, 0], [863, 1, 1, 48.0, 0, 0], [864, 3, 1, 29.69911764705882, 2, 0], [865, 2, 0, 24.0, 0, 0], [866, 2, 1, 42.0, 0, 0], [867, 2, 1, 27.0, 0, 2], [868, 1, 0, 31.0, 0, 0], [869, 3, 0, 29.69911764705882, 0, 0], [870, 3, 0, 4.0, 1, 0], [871, 3, 0, 26.0, 0, 0], [872, 1, 1, 47.0, 1, 0], [873, 1, 0, 33.0, 0, 0], [874, 3, 0, 47.0, 0, 0], [875, 2, 1, 28.0, 0, 2], [876, 3, 1, 15.0, 0, 2], [877, 3, 0, 20.0, 0, 0], [878, 3, 0, 19.0, 0, 0], [879, 3, 0, 29.69911764705882, 0, 0], [880, 1, 1, 56.0, 1, 2], [881, 2, 1, 25.0, 1, 0], [882, 3, 0, 33.0, 0, 0], [883, 3, 1, 22.0, 0, 0], [884, 2, 0, 28.0, 0, 0], [885, 3, 0, 25.0, 0, 0], [886, 3, 1, 39.0, 5, 1], [887, 2, 0, 27.0, 0, 0], [888, 1, 1, 19.0, 0, 0], [889, 3, 1, 29.69911764705882, 2, 0], [890, 1, 0, 26.0, 0, 2], [891, 3, 0, 32.0, 0, 1]]\n"
     ]
    }
   ],
   "source": [
    "x=[]\n",
    "for i, rows in train_data.iterrows():\n",
    "    x.append([\n",
    "    rows['PassengerId'],\n",
    "    rows['Pclass'],\n",
    "    #rows['Name'], #string\n",
    "    rows['Sex'], #string\n",
    "    rows['Age'],\n",
    "    rows['Parch'],\n",
    "    #rows['Ticket'], #string\n",
    "    #rows['Fare'], #string\n",
    "    rows['Embarked']] #string\n",
    "    )\n",
    "print(x)\n",
    "y=train_data['Survived'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "golden-liver",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-05T13:00:19.456899Z",
     "iopub.status.busy": "2021-07-05T13:00:19.456172Z",
     "iopub.status.idle": "2021-07-05T13:00:19.459269Z",
     "shell.execute_reply": "2021-07-05T13:00:19.458642Z",
     "shell.execute_reply.started": "2021-07-05T12:57:49.700425Z"
    },
    "papermill": {
     "duration": 0.02645,
     "end_time": "2021-07-05T13:00:19.459432",
     "exception": false,
     "start_time": "2021-07-05T13:00:19.432982",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 6)\n",
      "(891,)\n"
     ]
    }
   ],
   "source": [
    "print(np.array(x).shape)\n",
    "print(np.array(y).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "leading-lemon",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-05T13:00:19.500279Z",
     "iopub.status.busy": "2021-07-05T13:00:19.499520Z",
     "iopub.status.idle": "2021-07-05T13:00:49.923752Z",
     "shell.execute_reply": "2021-07-05T13:00:49.908838Z",
     "shell.execute_reply.started": "2021-07-05T12:57:49.712486Z"
    },
    "papermill": {
     "duration": 30.448451,
     "end_time": "2021-07-05T13:00:49.923996",
     "exception": false,
     "start_time": "2021-07-05T13:00:19.475545",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "28/28 [==============================] - 1s 1ms/step - loss: 0.6776 - accuracy: 0.6258\n",
      "Epoch 2/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.6563 - accuracy: 0.6349\n",
      "Epoch 3/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.6715 - accuracy: 0.6016\n",
      "Epoch 4/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.6579 - accuracy: 0.6395\n",
      "Epoch 5/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.6608 - accuracy: 0.6262\n",
      "Epoch 6/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.6417 - accuracy: 0.6385\n",
      "Epoch 7/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.6370 - accuracy: 0.6482\n",
      "Epoch 8/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.5997 - accuracy: 0.7084\n",
      "Epoch 9/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.5895 - accuracy: 0.7009\n",
      "Epoch 10/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.5406 - accuracy: 0.7430\n",
      "Epoch 11/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.5832 - accuracy: 0.6946\n",
      "Epoch 12/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.5339 - accuracy: 0.7107\n",
      "Epoch 13/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.5136 - accuracy: 0.7514\n",
      "Epoch 14/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.5692 - accuracy: 0.7142\n",
      "Epoch 15/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.5448 - accuracy: 0.7346\n",
      "Epoch 16/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.4895 - accuracy: 0.7696\n",
      "Epoch 17/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.4908 - accuracy: 0.7716\n",
      "Epoch 18/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4602 - accuracy: 0.8003\n",
      "Epoch 19/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.4799 - accuracy: 0.7894\n",
      "Epoch 20/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.5023 - accuracy: 0.7766\n",
      "Epoch 21/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.4473 - accuracy: 0.7946\n",
      "Epoch 22/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4677 - accuracy: 0.7871\n",
      "Epoch 23/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.4490 - accuracy: 0.8164\n",
      "Epoch 24/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4674 - accuracy: 0.7930\n",
      "Epoch 25/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4615 - accuracy: 0.7895\n",
      "Epoch 26/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4342 - accuracy: 0.7984\n",
      "Epoch 27/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4429 - accuracy: 0.8010\n",
      "Epoch 28/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4887 - accuracy: 0.7670\n",
      "Epoch 29/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4744 - accuracy: 0.8045\n",
      "Epoch 30/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4783 - accuracy: 0.7745\n",
      "Epoch 31/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.4496 - accuracy: 0.7946\n",
      "Epoch 32/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4774 - accuracy: 0.7820\n",
      "Epoch 33/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.4326 - accuracy: 0.8083\n",
      "Epoch 34/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.4744 - accuracy: 0.7801\n",
      "Epoch 35/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.4401 - accuracy: 0.8183\n",
      "Epoch 36/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.5120 - accuracy: 0.7538\n",
      "Epoch 37/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4422 - accuracy: 0.8167\n",
      "Epoch 38/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.4785 - accuracy: 0.7854\n",
      "Epoch 39/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.4402 - accuracy: 0.8177\n",
      "Epoch 40/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4714 - accuracy: 0.7919\n",
      "Epoch 41/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.4495 - accuracy: 0.7964\n",
      "Epoch 42/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4449 - accuracy: 0.7979\n",
      "Epoch 43/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.4730 - accuracy: 0.7838\n",
      "Epoch 44/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.4492 - accuracy: 0.8173\n",
      "Epoch 45/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.4123 - accuracy: 0.8165\n",
      "Epoch 46/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4215 - accuracy: 0.8043\n",
      "Epoch 47/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4429 - accuracy: 0.8080\n",
      "Epoch 48/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4615 - accuracy: 0.7871\n",
      "Epoch 49/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4283 - accuracy: 0.8208\n",
      "Epoch 50/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4423 - accuracy: 0.8119\n",
      "Epoch 51/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4344 - accuracy: 0.8171\n",
      "Epoch 52/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.4332 - accuracy: 0.7966\n",
      "Epoch 53/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.4635 - accuracy: 0.7981\n",
      "Epoch 54/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.4798 - accuracy: 0.7692\n",
      "Epoch 55/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.3977 - accuracy: 0.8196\n",
      "Epoch 56/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4415 - accuracy: 0.7981\n",
      "Epoch 57/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.4505 - accuracy: 0.7953\n",
      "Epoch 58/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4438 - accuracy: 0.8002\n",
      "Epoch 59/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4325 - accuracy: 0.8096\n",
      "Epoch 60/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4488 - accuracy: 0.8018\n",
      "Epoch 61/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4215 - accuracy: 0.8174\n",
      "Epoch 62/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3966 - accuracy: 0.8364\n",
      "Epoch 63/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4497 - accuracy: 0.7961\n",
      "Epoch 64/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4307 - accuracy: 0.8111\n",
      "Epoch 65/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4266 - accuracy: 0.8235\n",
      "Epoch 66/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4074 - accuracy: 0.8157\n",
      "Epoch 67/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4645 - accuracy: 0.7877\n",
      "Epoch 68/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4425 - accuracy: 0.8055\n",
      "Epoch 69/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.4421 - accuracy: 0.7937\n",
      "Epoch 70/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.5199 - accuracy: 0.7663\n",
      "Epoch 71/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4503 - accuracy: 0.8048\n",
      "Epoch 72/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4808 - accuracy: 0.7861\n",
      "Epoch 73/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4427 - accuracy: 0.7903\n",
      "Epoch 74/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4176 - accuracy: 0.8293\n",
      "Epoch 75/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4660 - accuracy: 0.7865\n",
      "Epoch 76/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4517 - accuracy: 0.7990\n",
      "Epoch 77/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4138 - accuracy: 0.8144\n",
      "Epoch 78/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.5573 - accuracy: 0.7449\n",
      "Epoch 79/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.4164 - accuracy: 0.8236\n",
      "Epoch 80/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4569 - accuracy: 0.7953\n",
      "Epoch 81/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4152 - accuracy: 0.8263\n",
      "Epoch 82/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.3927 - accuracy: 0.8326\n",
      "Epoch 83/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4298 - accuracy: 0.8093\n",
      "Epoch 84/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4664 - accuracy: 0.7884\n",
      "Epoch 85/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4268 - accuracy: 0.8106\n",
      "Epoch 86/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4214 - accuracy: 0.8085\n",
      "Epoch 87/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4419 - accuracy: 0.8068\n",
      "Epoch 88/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4666 - accuracy: 0.7952\n",
      "Epoch 89/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4161 - accuracy: 0.8158\n",
      "Epoch 90/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4317 - accuracy: 0.8073\n",
      "Epoch 91/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4230 - accuracy: 0.8086\n",
      "Epoch 92/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.5070 - accuracy: 0.7667\n",
      "Epoch 93/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3954 - accuracy: 0.8207\n",
      "Epoch 94/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4348 - accuracy: 0.8001\n",
      "Epoch 95/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4186 - accuracy: 0.8283\n",
      "Epoch 96/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4237 - accuracy: 0.8108\n",
      "Epoch 97/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4226 - accuracy: 0.8091\n",
      "Epoch 98/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.4099 - accuracy: 0.8150\n",
      "Epoch 99/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.4357 - accuracy: 0.7908\n",
      "Epoch 100/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4189 - accuracy: 0.8254\n",
      "Epoch 101/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4419 - accuracy: 0.8068\n",
      "Epoch 102/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4470 - accuracy: 0.8214\n",
      "Epoch 103/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4083 - accuracy: 0.8280\n",
      "Epoch 104/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4284 - accuracy: 0.8082\n",
      "Epoch 105/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4257 - accuracy: 0.8192\n",
      "Epoch 106/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4036 - accuracy: 0.8178\n",
      "Epoch 107/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4041 - accuracy: 0.8383\n",
      "Epoch 108/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.4346 - accuracy: 0.7926\n",
      "Epoch 109/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.4537 - accuracy: 0.7929\n",
      "Epoch 110/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4126 - accuracy: 0.8144\n",
      "Epoch 111/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.4071 - accuracy: 0.8197\n",
      "Epoch 112/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.4424 - accuracy: 0.7943\n",
      "Epoch 113/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4418 - accuracy: 0.8228\n",
      "Epoch 114/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4549 - accuracy: 0.7945\n",
      "Epoch 115/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4425 - accuracy: 0.7914\n",
      "Epoch 116/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4468 - accuracy: 0.8032\n",
      "Epoch 117/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4857 - accuracy: 0.7841\n",
      "Epoch 118/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3925 - accuracy: 0.8246\n",
      "Epoch 119/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4028 - accuracy: 0.8269\n",
      "Epoch 120/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4393 - accuracy: 0.8048\n",
      "Epoch 121/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4264 - accuracy: 0.8098\n",
      "Epoch 122/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4975 - accuracy: 0.7795\n",
      "Epoch 123/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4578 - accuracy: 0.7972\n",
      "Epoch 124/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4499 - accuracy: 0.8034\n",
      "Epoch 125/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.4214 - accuracy: 0.8255\n",
      "Epoch 126/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4491 - accuracy: 0.7948\n",
      "Epoch 127/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4277 - accuracy: 0.8001\n",
      "Epoch 128/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4234 - accuracy: 0.8219\n",
      "Epoch 129/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.4067 - accuracy: 0.8131\n",
      "Epoch 130/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4090 - accuracy: 0.8183\n",
      "Epoch 131/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4093 - accuracy: 0.8107\n",
      "Epoch 132/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3980 - accuracy: 0.8458\n",
      "Epoch 133/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4296 - accuracy: 0.8098\n",
      "Epoch 134/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4228 - accuracy: 0.8215\n",
      "Epoch 135/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4292 - accuracy: 0.8036\n",
      "Epoch 136/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.4165 - accuracy: 0.8244\n",
      "Epoch 137/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4116 - accuracy: 0.8189\n",
      "Epoch 138/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4376 - accuracy: 0.7968\n",
      "Epoch 139/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4352 - accuracy: 0.8060\n",
      "Epoch 140/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4222 - accuracy: 0.8076\n",
      "Epoch 141/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4518 - accuracy: 0.7985\n",
      "Epoch 142/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4014 - accuracy: 0.8297\n",
      "Epoch 143/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4235 - accuracy: 0.8095\n",
      "Epoch 144/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4028 - accuracy: 0.8352\n",
      "Epoch 145/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.4053 - accuracy: 0.8180\n",
      "Epoch 146/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4175 - accuracy: 0.7977\n",
      "Epoch 147/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4194 - accuracy: 0.8059\n",
      "Epoch 148/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.4408 - accuracy: 0.7902\n",
      "Epoch 149/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4070 - accuracy: 0.8280\n",
      "Epoch 150/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.4049 - accuracy: 0.8102\n",
      "Epoch 151/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.4171 - accuracy: 0.8212\n",
      "Epoch 152/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3977 - accuracy: 0.8226\n",
      "Epoch 153/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4760 - accuracy: 0.7862\n",
      "Epoch 154/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4421 - accuracy: 0.8172\n",
      "Epoch 155/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4421 - accuracy: 0.8052\n",
      "Epoch 156/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4249 - accuracy: 0.8147\n",
      "Epoch 157/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4237 - accuracy: 0.8138\n",
      "Epoch 158/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4174 - accuracy: 0.8106\n",
      "Epoch 159/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4108 - accuracy: 0.8268\n",
      "Epoch 160/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4134 - accuracy: 0.8173\n",
      "Epoch 161/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4118 - accuracy: 0.8095\n",
      "Epoch 162/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4313 - accuracy: 0.8004\n",
      "Epoch 163/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3958 - accuracy: 0.8238\n",
      "Epoch 164/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4139 - accuracy: 0.8278\n",
      "Epoch 165/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4176 - accuracy: 0.8106\n",
      "Epoch 166/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4057 - accuracy: 0.8284\n",
      "Epoch 167/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4277 - accuracy: 0.8219\n",
      "Epoch 168/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3785 - accuracy: 0.8287\n",
      "Epoch 169/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.3946 - accuracy: 0.8273\n",
      "Epoch 170/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3795 - accuracy: 0.8413\n",
      "Epoch 171/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4144 - accuracy: 0.8211\n",
      "Epoch 172/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3992 - accuracy: 0.8387\n",
      "Epoch 173/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3993 - accuracy: 0.8330\n",
      "Epoch 174/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3845 - accuracy: 0.8365\n",
      "Epoch 175/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4082 - accuracy: 0.8128\n",
      "Epoch 176/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4089 - accuracy: 0.8164\n",
      "Epoch 177/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3999 - accuracy: 0.8371\n",
      "Epoch 178/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4008 - accuracy: 0.8229\n",
      "Epoch 179/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4409 - accuracy: 0.7978\n",
      "Epoch 180/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4344 - accuracy: 0.8109\n",
      "Epoch 181/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4001 - accuracy: 0.8202\n",
      "Epoch 182/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3913 - accuracy: 0.8312\n",
      "Epoch 183/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4315 - accuracy: 0.8079\n",
      "Epoch 184/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3821 - accuracy: 0.8335\n",
      "Epoch 185/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4297 - accuracy: 0.7930\n",
      "Epoch 186/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3877 - accuracy: 0.8457\n",
      "Epoch 187/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4081 - accuracy: 0.8157\n",
      "Epoch 188/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3738 - accuracy: 0.8285\n",
      "Epoch 189/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4250 - accuracy: 0.8094\n",
      "Epoch 190/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3943 - accuracy: 0.8248\n",
      "Epoch 191/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3881 - accuracy: 0.8317\n",
      "Epoch 192/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4322 - accuracy: 0.7990\n",
      "Epoch 193/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3956 - accuracy: 0.8291\n",
      "Epoch 194/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.3831 - accuracy: 0.8262\n",
      "Epoch 195/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.4078 - accuracy: 0.8210\n",
      "Epoch 196/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.4079 - accuracy: 0.8263\n",
      "Epoch 197/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.3835 - accuracy: 0.8434\n",
      "Epoch 198/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.4066 - accuracy: 0.8115\n",
      "Epoch 199/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3708 - accuracy: 0.8475\n",
      "Epoch 200/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4132 - accuracy: 0.8121\n",
      "Epoch 201/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.4305 - accuracy: 0.8166\n",
      "Epoch 202/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4042 - accuracy: 0.8346\n",
      "Epoch 203/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4149 - accuracy: 0.8323\n",
      "Epoch 204/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3831 - accuracy: 0.8431\n",
      "Epoch 205/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4177 - accuracy: 0.8209\n",
      "Epoch 206/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3863 - accuracy: 0.8340\n",
      "Epoch 207/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4057 - accuracy: 0.8299\n",
      "Epoch 208/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4006 - accuracy: 0.8261\n",
      "Epoch 209/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4799 - accuracy: 0.7923\n",
      "Epoch 210/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.3867 - accuracy: 0.8250\n",
      "Epoch 211/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.3900 - accuracy: 0.8284\n",
      "Epoch 212/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4065 - accuracy: 0.8175\n",
      "Epoch 213/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4344 - accuracy: 0.8187\n",
      "Epoch 214/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4082 - accuracy: 0.8310\n",
      "Epoch 215/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4120 - accuracy: 0.8236\n",
      "Epoch 216/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.3959 - accuracy: 0.8249\n",
      "Epoch 217/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.4257 - accuracy: 0.8209\n",
      "Epoch 218/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3946 - accuracy: 0.8271\n",
      "Epoch 219/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4171 - accuracy: 0.8056\n",
      "Epoch 220/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.4242 - accuracy: 0.8102\n",
      "Epoch 221/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.4047 - accuracy: 0.8222\n",
      "Epoch 222/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.3988 - accuracy: 0.8191\n",
      "Epoch 223/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.4024 - accuracy: 0.8373\n",
      "Epoch 224/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.3805 - accuracy: 0.8367\n",
      "Epoch 225/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3795 - accuracy: 0.8352\n",
      "Epoch 226/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3886 - accuracy: 0.8299\n",
      "Epoch 227/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.4043 - accuracy: 0.8163\n",
      "Epoch 228/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.3709 - accuracy: 0.8351\n",
      "Epoch 229/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4083 - accuracy: 0.8270\n",
      "Epoch 230/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.3554 - accuracy: 0.8624\n",
      "Epoch 231/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3998 - accuracy: 0.8318\n",
      "Epoch 232/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.3886 - accuracy: 0.8192\n",
      "Epoch 233/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.3931 - accuracy: 0.8281\n",
      "Epoch 234/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4000 - accuracy: 0.8050\n",
      "Epoch 235/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4258 - accuracy: 0.8099\n",
      "Epoch 236/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3628 - accuracy: 0.8569\n",
      "Epoch 237/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.4028 - accuracy: 0.8233\n",
      "Epoch 238/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.4128 - accuracy: 0.8244\n",
      "Epoch 239/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3812 - accuracy: 0.8574\n",
      "Epoch 240/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4229 - accuracy: 0.8082\n",
      "Epoch 241/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.4454 - accuracy: 0.7871\n",
      "Epoch 242/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3931 - accuracy: 0.8259\n",
      "Epoch 243/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4003 - accuracy: 0.8327\n",
      "Epoch 244/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4339 - accuracy: 0.8008\n",
      "Epoch 245/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3834 - accuracy: 0.8433\n",
      "Epoch 246/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3681 - accuracy: 0.8355\n",
      "Epoch 247/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.4001 - accuracy: 0.8339\n",
      "Epoch 248/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.4251 - accuracy: 0.8085\n",
      "Epoch 249/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3866 - accuracy: 0.8373\n",
      "Epoch 250/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4089 - accuracy: 0.8298\n",
      "Epoch 251/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.4206 - accuracy: 0.8275\n",
      "Epoch 252/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.4029 - accuracy: 0.8409\n",
      "Epoch 253/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.3860 - accuracy: 0.8270\n",
      "Epoch 254/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.3961 - accuracy: 0.8374\n",
      "Epoch 255/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4055 - accuracy: 0.8177\n",
      "Epoch 256/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.4608 - accuracy: 0.7905\n",
      "Epoch 257/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.4073 - accuracy: 0.8032\n",
      "Epoch 258/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.4274 - accuracy: 0.8146\n",
      "Epoch 259/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.3924 - accuracy: 0.8345\n",
      "Epoch 260/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.3661 - accuracy: 0.8474\n",
      "Epoch 261/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3888 - accuracy: 0.8165\n",
      "Epoch 262/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.4051 - accuracy: 0.8306\n",
      "Epoch 263/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4020 - accuracy: 0.8264\n",
      "Epoch 264/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3836 - accuracy: 0.8256\n",
      "Epoch 265/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.3855 - accuracy: 0.8453\n",
      "Epoch 266/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.3756 - accuracy: 0.8502\n",
      "Epoch 267/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.3798 - accuracy: 0.8406\n",
      "Epoch 268/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3586 - accuracy: 0.8384\n",
      "Epoch 269/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.3966 - accuracy: 0.8344\n",
      "Epoch 270/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4247 - accuracy: 0.8183\n",
      "Epoch 271/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4116 - accuracy: 0.8072\n",
      "Epoch 272/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4131 - accuracy: 0.8334\n",
      "Epoch 273/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3765 - accuracy: 0.8374\n",
      "Epoch 274/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4091 - accuracy: 0.8260\n",
      "Epoch 275/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4154 - accuracy: 0.8149\n",
      "Epoch 276/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3852 - accuracy: 0.8265\n",
      "Epoch 277/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4263 - accuracy: 0.8125\n",
      "Epoch 278/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.3784 - accuracy: 0.8460\n",
      "Epoch 279/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3753 - accuracy: 0.8493\n",
      "Epoch 280/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.3458 - accuracy: 0.8458\n",
      "Epoch 281/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4058 - accuracy: 0.8161\n",
      "Epoch 282/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3850 - accuracy: 0.8333\n",
      "Epoch 283/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4279 - accuracy: 0.8209\n",
      "Epoch 284/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3612 - accuracy: 0.8486\n",
      "Epoch 285/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3719 - accuracy: 0.8377\n",
      "Epoch 286/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.3992 - accuracy: 0.8342\n",
      "Epoch 287/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4050 - accuracy: 0.8119\n",
      "Epoch 288/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3738 - accuracy: 0.8425\n",
      "Epoch 289/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4124 - accuracy: 0.8383\n",
      "Epoch 290/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3888 - accuracy: 0.8290\n",
      "Epoch 291/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3960 - accuracy: 0.8344\n",
      "Epoch 292/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4051 - accuracy: 0.8236\n",
      "Epoch 293/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3643 - accuracy: 0.8473\n",
      "Epoch 294/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3873 - accuracy: 0.8211\n",
      "Epoch 295/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3705 - accuracy: 0.8448\n",
      "Epoch 296/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.3706 - accuracy: 0.8371\n",
      "Epoch 297/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3760 - accuracy: 0.8430\n",
      "Epoch 298/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4002 - accuracy: 0.8216\n",
      "Epoch 299/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4098 - accuracy: 0.8159\n",
      "Epoch 300/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4025 - accuracy: 0.8143\n",
      "Epoch 301/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.3718 - accuracy: 0.8496\n",
      "Epoch 302/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.3928 - accuracy: 0.8220\n",
      "Epoch 303/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3940 - accuracy: 0.8242\n",
      "Epoch 304/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3798 - accuracy: 0.8407\n",
      "Epoch 305/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3745 - accuracy: 0.8422\n",
      "Epoch 306/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3901 - accuracy: 0.8222\n",
      "Epoch 307/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4069 - accuracy: 0.8229\n",
      "Epoch 308/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3765 - accuracy: 0.8531\n",
      "Epoch 309/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.3907 - accuracy: 0.8310\n",
      "Epoch 310/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4012 - accuracy: 0.8115\n",
      "Epoch 311/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3714 - accuracy: 0.8478\n",
      "Epoch 312/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.3870 - accuracy: 0.8389\n",
      "Epoch 313/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4036 - accuracy: 0.8230\n",
      "Epoch 314/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3917 - accuracy: 0.8303\n",
      "Epoch 315/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.3861 - accuracy: 0.8396\n",
      "Epoch 316/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4004 - accuracy: 0.8332\n",
      "Epoch 317/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4241 - accuracy: 0.8022\n",
      "Epoch 318/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3898 - accuracy: 0.8250\n",
      "Epoch 319/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3799 - accuracy: 0.8506\n",
      "Epoch 320/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3936 - accuracy: 0.8251\n",
      "Epoch 321/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3601 - accuracy: 0.8515\n",
      "Epoch 322/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4090 - accuracy: 0.8269\n",
      "Epoch 323/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4318 - accuracy: 0.8072\n",
      "Epoch 324/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4109 - accuracy: 0.8329\n",
      "Epoch 325/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3715 - accuracy: 0.8531\n",
      "Epoch 326/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.3973 - accuracy: 0.8079\n",
      "Epoch 327/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3941 - accuracy: 0.8151\n",
      "Epoch 328/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3984 - accuracy: 0.8241\n",
      "Epoch 329/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3526 - accuracy: 0.8537\n",
      "Epoch 330/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3768 - accuracy: 0.8428\n",
      "Epoch 331/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4026 - accuracy: 0.8255\n",
      "Epoch 332/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3956 - accuracy: 0.8105\n",
      "Epoch 333/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4019 - accuracy: 0.8168\n",
      "Epoch 334/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4027 - accuracy: 0.8128\n",
      "Epoch 335/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.3626 - accuracy: 0.8422\n",
      "Epoch 336/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3847 - accuracy: 0.8302\n",
      "Epoch 337/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3690 - accuracy: 0.8421\n",
      "Epoch 338/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.3930 - accuracy: 0.8368\n",
      "Epoch 339/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.3849 - accuracy: 0.8347\n",
      "Epoch 340/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4065 - accuracy: 0.8267\n",
      "Epoch 341/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3656 - accuracy: 0.8451\n",
      "Epoch 342/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.4080 - accuracy: 0.8061\n",
      "Epoch 343/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3711 - accuracy: 0.8523\n",
      "Epoch 344/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.4123 - accuracy: 0.8207\n",
      "Epoch 345/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4009 - accuracy: 0.8227\n",
      "Epoch 346/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.4053 - accuracy: 0.8251\n",
      "Epoch 347/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.3712 - accuracy: 0.8448\n",
      "Epoch 348/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.3755 - accuracy: 0.8299\n",
      "Epoch 349/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3787 - accuracy: 0.8457\n",
      "Epoch 350/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4189 - accuracy: 0.8102\n",
      "Epoch 351/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4354 - accuracy: 0.8001\n",
      "Epoch 352/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3865 - accuracy: 0.8355\n",
      "Epoch 353/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4101 - accuracy: 0.8269\n",
      "Epoch 354/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3693 - accuracy: 0.8496\n",
      "Epoch 355/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4154 - accuracy: 0.8102\n",
      "Epoch 356/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4377 - accuracy: 0.8141\n",
      "Epoch 357/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3720 - accuracy: 0.8294\n",
      "Epoch 358/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.3672 - accuracy: 0.8409\n",
      "Epoch 359/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4203 - accuracy: 0.8086\n",
      "Epoch 360/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3817 - accuracy: 0.8392\n",
      "Epoch 361/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3896 - accuracy: 0.8268\n",
      "Epoch 362/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3766 - accuracy: 0.8345\n",
      "Epoch 363/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3733 - accuracy: 0.8297\n",
      "Epoch 364/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3757 - accuracy: 0.8357\n",
      "Epoch 365/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3708 - accuracy: 0.8483\n",
      "Epoch 366/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3631 - accuracy: 0.8480\n",
      "Epoch 367/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4014 - accuracy: 0.8110\n",
      "Epoch 368/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3657 - accuracy: 0.8482\n",
      "Epoch 369/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.3922 - accuracy: 0.8333\n",
      "Epoch 370/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.3570 - accuracy: 0.8465\n",
      "Epoch 371/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.3868 - accuracy: 0.8476\n",
      "Epoch 372/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.3907 - accuracy: 0.8190\n",
      "Epoch 373/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.3939 - accuracy: 0.8232\n",
      "Epoch 374/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3947 - accuracy: 0.8309\n",
      "Epoch 375/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3790 - accuracy: 0.8390\n",
      "Epoch 376/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3791 - accuracy: 0.8166\n",
      "Epoch 377/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4025 - accuracy: 0.8249\n",
      "Epoch 378/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3905 - accuracy: 0.8311\n",
      "Epoch 379/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3641 - accuracy: 0.8442\n",
      "Epoch 380/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4035 - accuracy: 0.8200\n",
      "Epoch 381/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3611 - accuracy: 0.8378\n",
      "Epoch 382/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3597 - accuracy: 0.8376\n",
      "Epoch 383/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3766 - accuracy: 0.8326\n",
      "Epoch 384/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.3812 - accuracy: 0.8349\n",
      "Epoch 385/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.4223 - accuracy: 0.8124\n",
      "Epoch 386/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.3988 - accuracy: 0.8350\n",
      "Epoch 387/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.3788 - accuracy: 0.8328\n",
      "Epoch 388/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.3628 - accuracy: 0.8485\n",
      "Epoch 389/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.3877 - accuracy: 0.8397\n",
      "Epoch 390/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4126 - accuracy: 0.8108\n",
      "Epoch 391/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.3881 - accuracy: 0.8342\n",
      "Epoch 392/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.3857 - accuracy: 0.8342\n",
      "Epoch 393/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.3943 - accuracy: 0.8259\n",
      "Epoch 394/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3593 - accuracy: 0.8525\n",
      "Epoch 395/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3404 - accuracy: 0.8540\n",
      "Epoch 396/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3481 - accuracy: 0.8437\n",
      "Epoch 397/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.4017 - accuracy: 0.8243\n",
      "Epoch 398/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3845 - accuracy: 0.8320\n",
      "Epoch 399/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3953 - accuracy: 0.8207\n",
      "Epoch 400/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3527 - accuracy: 0.8478\n",
      "Epoch 401/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3515 - accuracy: 0.8459\n",
      "Epoch 402/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3673 - accuracy: 0.8393\n",
      "Epoch 403/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3931 - accuracy: 0.8220\n",
      "Epoch 404/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3543 - accuracy: 0.8501\n",
      "Epoch 405/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4041 - accuracy: 0.8248\n",
      "Epoch 406/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3546 - accuracy: 0.8513\n",
      "Epoch 407/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.3524 - accuracy: 0.8413\n",
      "Epoch 408/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3775 - accuracy: 0.8413\n",
      "Epoch 409/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3557 - accuracy: 0.8570\n",
      "Epoch 410/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3732 - accuracy: 0.8287\n",
      "Epoch 411/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3717 - accuracy: 0.8534\n",
      "Epoch 412/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.3722 - accuracy: 0.8502\n",
      "Epoch 413/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3710 - accuracy: 0.8388\n",
      "Epoch 414/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.3855 - accuracy: 0.8253\n",
      "Epoch 415/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3772 - accuracy: 0.8471\n",
      "Epoch 416/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3487 - accuracy: 0.8608\n",
      "Epoch 417/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3647 - accuracy: 0.8476\n",
      "Epoch 418/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3794 - accuracy: 0.8371\n",
      "Epoch 419/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.4072 - accuracy: 0.8393\n",
      "Epoch 420/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3676 - accuracy: 0.8436\n",
      "Epoch 421/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3892 - accuracy: 0.8346\n",
      "Epoch 422/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3712 - accuracy: 0.8417\n",
      "Epoch 423/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.3472 - accuracy: 0.8584\n",
      "Epoch 424/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3629 - accuracy: 0.8526\n",
      "Epoch 425/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3909 - accuracy: 0.8371\n",
      "Epoch 426/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3474 - accuracy: 0.8640\n",
      "Epoch 427/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3526 - accuracy: 0.8381\n",
      "Epoch 428/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4194 - accuracy: 0.8387\n",
      "Epoch 429/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4065 - accuracy: 0.8222\n",
      "Epoch 430/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3450 - accuracy: 0.8622\n",
      "Epoch 431/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3966 - accuracy: 0.8239\n",
      "Epoch 432/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.3637 - accuracy: 0.8449\n",
      "Epoch 433/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3986 - accuracy: 0.8243\n",
      "Epoch 434/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3721 - accuracy: 0.8408\n",
      "Epoch 435/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3729 - accuracy: 0.8408\n",
      "Epoch 436/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3725 - accuracy: 0.8396\n",
      "Epoch 437/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.3917 - accuracy: 0.8250\n",
      "Epoch 438/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4048 - accuracy: 0.8318\n",
      "Epoch 439/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3499 - accuracy: 0.8629\n",
      "Epoch 440/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3823 - accuracy: 0.8440\n",
      "Epoch 441/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4026 - accuracy: 0.8195\n",
      "Epoch 442/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3731 - accuracy: 0.8288\n",
      "Epoch 443/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3854 - accuracy: 0.8197\n",
      "Epoch 444/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3538 - accuracy: 0.8513\n",
      "Epoch 445/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3824 - accuracy: 0.8390\n",
      "Epoch 446/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3714 - accuracy: 0.8486\n",
      "Epoch 447/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3382 - accuracy: 0.8657\n",
      "Epoch 448/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3907 - accuracy: 0.8281\n",
      "Epoch 449/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3811 - accuracy: 0.8233\n",
      "Epoch 450/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4016 - accuracy: 0.8253\n",
      "Epoch 451/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3889 - accuracy: 0.8287\n",
      "Epoch 452/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3572 - accuracy: 0.8368\n",
      "Epoch 453/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3726 - accuracy: 0.8490\n",
      "Epoch 454/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3730 - accuracy: 0.8498\n",
      "Epoch 455/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.3478 - accuracy: 0.8511\n",
      "Epoch 456/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3818 - accuracy: 0.8401\n",
      "Epoch 457/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3979 - accuracy: 0.8207\n",
      "Epoch 458/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3591 - accuracy: 0.8472\n",
      "Epoch 459/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3695 - accuracy: 0.8455\n",
      "Epoch 460/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3876 - accuracy: 0.8256\n",
      "Epoch 461/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3916 - accuracy: 0.8269\n",
      "Epoch 462/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3805 - accuracy: 0.8353\n",
      "Epoch 463/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3918 - accuracy: 0.8208\n",
      "Epoch 464/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3736 - accuracy: 0.8358\n",
      "Epoch 465/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4180 - accuracy: 0.8271\n",
      "Epoch 466/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4378 - accuracy: 0.8101\n",
      "Epoch 467/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3635 - accuracy: 0.8538\n",
      "Epoch 468/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3384 - accuracy: 0.8610\n",
      "Epoch 469/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3640 - accuracy: 0.8432\n",
      "Epoch 470/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.3861 - accuracy: 0.8346\n",
      "Epoch 471/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3580 - accuracy: 0.8495\n",
      "Epoch 472/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3647 - accuracy: 0.8383\n",
      "Epoch 473/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3736 - accuracy: 0.8319\n",
      "Epoch 474/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3583 - accuracy: 0.8426\n",
      "Epoch 475/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.3864 - accuracy: 0.8380\n",
      "Epoch 476/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4078 - accuracy: 0.8094\n",
      "Epoch 477/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.3735 - accuracy: 0.8401\n",
      "Epoch 478/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3863 - accuracy: 0.8334\n",
      "Epoch 479/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.3555 - accuracy: 0.8417\n",
      "Epoch 480/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.4013 - accuracy: 0.8263\n",
      "Epoch 481/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3580 - accuracy: 0.8421\n",
      "Epoch 482/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3927 - accuracy: 0.8314\n",
      "Epoch 483/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.4084 - accuracy: 0.8051\n",
      "Epoch 484/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.4051 - accuracy: 0.8195\n",
      "Epoch 485/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.3696 - accuracy: 0.8405\n",
      "Epoch 486/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3578 - accuracy: 0.8348\n",
      "Epoch 487/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3531 - accuracy: 0.8680\n",
      "Epoch 488/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3830 - accuracy: 0.8254\n",
      "Epoch 489/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3512 - accuracy: 0.8552\n",
      "Epoch 490/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3590 - accuracy: 0.8438\n",
      "Epoch 491/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3508 - accuracy: 0.8602\n",
      "Epoch 492/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3682 - accuracy: 0.8430\n",
      "Epoch 493/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3793 - accuracy: 0.8343\n",
      "Epoch 494/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3757 - accuracy: 0.8425\n",
      "Epoch 495/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3950 - accuracy: 0.8200\n",
      "Epoch 496/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3778 - accuracy: 0.8347\n",
      "Epoch 497/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3697 - accuracy: 0.8454\n",
      "Epoch 498/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.3799 - accuracy: 0.8328\n",
      "Epoch 499/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3903 - accuracy: 0.8351\n",
      "Epoch 500/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3555 - accuracy: 0.8495\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "model=tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(64,activation='tanh'),\n",
    "    tf.keras.layers.Dense(128,activation='tanh'),\n",
    "    tf.keras.layers.Dense(1,activation='sigmoid'),\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
    "think=model.fit(np.array(x),np.array(y),epochs=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fluid-petersburg",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-05T13:00:50.617588Z",
     "iopub.status.busy": "2021-07-05T13:00:50.616887Z",
     "iopub.status.idle": "2021-07-05T13:00:50.623856Z",
     "shell.execute_reply": "2021-07-05T13:00:50.623244Z",
     "shell.execute_reply.started": "2021-07-05T12:58:16.618523Z"
    },
    "papermill": {
     "duration": 0.353001,
     "end_time": "2021-07-05T13:00:50.624030",
     "exception": false,
     "start_time": "2021-07-05T13:00:50.271029",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     PassengerId  Pclass                                          Name  \\\n",
      "0            892       3                              Kelly, Mr. James   \n",
      "1            893       3              Wilkes, Mrs. James (Ellen Needs)   \n",
      "2            894       2                     Myles, Mr. Thomas Francis   \n",
      "3            895       3                              Wirz, Mr. Albert   \n",
      "4            896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)   \n",
      "..           ...     ...                                           ...   \n",
      "413         1305       3                            Spector, Mr. Woolf   \n",
      "414         1306       1                  Oliva y Ocana, Dona. Fermina   \n",
      "415         1307       3                  Saether, Mr. Simon Sivertsen   \n",
      "416         1308       3                           Ware, Mr. Frederick   \n",
      "417         1309       3                      Peter, Master. Michael J   \n",
      "\n",
      "        Sex       Age  SibSp  Parch              Ticket      Fare Cabin  \\\n",
      "0         1  34.50000      0      0              330911    7.8292   NaN   \n",
      "1    female  47.00000      1      0              363272    7.0000   NaN   \n",
      "2         1  62.00000      0      0              240276    9.6875   NaN   \n",
      "3         1  27.00000      0      0              315154    8.6625   NaN   \n",
      "4    female  22.00000      1      1             3101298   12.2875   NaN   \n",
      "..      ...       ...    ...    ...                 ...       ...   ...   \n",
      "413    male  30.27259      0      0           A.5. 3236    8.0500   NaN   \n",
      "414  female  39.00000      0      0            PC 17758  108.9000  C105   \n",
      "415    male  38.50000      0      0  SOTON/O.Q. 3101262    7.2500   NaN   \n",
      "416    male  30.27259      0      0              359309    8.0500   NaN   \n",
      "417    male  30.27259      1      1                2668   22.3583   NaN   \n",
      "\n",
      "    Embarked  \n",
      "0          Q  \n",
      "1          S  \n",
      "2          Q  \n",
      "3          S  \n",
      "4          S  \n",
      "..       ...  \n",
      "413        S  \n",
      "414        C  \n",
      "415        S  \n",
      "416        S  \n",
      "417        C  \n",
      "\n",
      "[418 rows x 11 columns]\n",
      "PassengerId      0\n",
      "Pclass           0\n",
      "Name             0\n",
      "Sex              0\n",
      "Age              0\n",
      "SibSp            0\n",
      "Parch            0\n",
      "Ticket           0\n",
      "Fare             0\n",
      "Cabin          327\n",
      "Embarked         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#test data에 대해서도 text 1 결측값 처리 2 숫자로 바꾸기 3 list형으로 바꾸기 함.\n",
    "#1 결측값 처리\n",
    "test_data.loc[test_data.Age.isnull(),'Age']=test_data.Age.mean() #Age 결측 평균채우기\n",
    "print(test_data)\n",
    "test_data.loc[test_data.Fare.isnull(),'Fare']=test_data.Fare.mean() #Embarked 결측 최빈값 채우기\n",
    "print(test_data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "quantitative-digest",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-05T13:00:51.291962Z",
     "iopub.status.busy": "2021-07-05T13:00:51.286627Z",
     "iopub.status.idle": "2021-07-05T13:00:51.339365Z",
     "shell.execute_reply": "2021-07-05T13:00:51.338584Z",
     "shell.execute_reply.started": "2021-07-05T12:58:16.64244Z"
    },
    "papermill": {
     "duration": 0.390213,
     "end_time": "2021-07-05T13:00:51.339536",
     "exception": false,
     "start_time": "2021-07-05T13:00:50.949323",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#2 숫자로 바꾸기\n",
    "test_data.loc[test_data.Sex=='female','Sex']=1\n",
    "test_data.loc[test_data.Sex=='male','Sex']=0\n",
    "test_data.loc[test_data.Embarked=='S','Embarked']=0\n",
    "test_data.loc[test_data.Embarked=='Q','Embarked']=1\n",
    "test_data.loc[test_data.Embarked=='C','Embarked']=2\n",
    "#text data인 Sex, Embarked 를 측정 가능한 숫자로 바꿈.\n",
    "#3\n",
    "testx=[]\n",
    "for i, rows in test_data.iterrows():\n",
    "    testx.append([\n",
    "    rows['PassengerId'],\n",
    "    rows['Pclass'],\n",
    "    #rows['Name'], #string\n",
    "    rows['Sex'], #string\n",
    "    rows['Age'],\n",
    "    rows['Parch'],\n",
    "    #rows['Ticket'], #string\n",
    "    #rows['Fare'], #string\n",
    "    rows['Embarked']] #string\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "determined-discrimination",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-05T13:00:52.006234Z",
     "iopub.status.busy": "2021-07-05T13:00:52.004832Z",
     "iopub.status.idle": "2021-07-05T13:00:52.010292Z",
     "shell.execute_reply": "2021-07-05T13:00:52.009598Z",
     "shell.execute_reply.started": "2021-07-05T12:58:16.704199Z"
    },
    "papermill": {
     "duration": 0.350174,
     "end_time": "2021-07-05T13:00:52.010473",
     "exception": false,
     "start_time": "2021-07-05T13:00:51.660299",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      0\n",
       "Pclass           0\n",
       "Name             0\n",
       "Sex              0\n",
       "Age              0\n",
       "SibSp            0\n",
       "Parch            0\n",
       "Ticket           0\n",
       "Fare             0\n",
       "Cabin          327\n",
       "Embarked         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "wireless-hartford",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-05T13:00:52.673183Z",
     "iopub.status.busy": "2021-07-05T13:00:52.672098Z",
     "iopub.status.idle": "2021-07-05T13:00:52.880776Z",
     "shell.execute_reply": "2021-07-05T13:00:52.880021Z",
     "shell.execute_reply.started": "2021-07-05T12:58:46.025441Z"
    },
    "papermill": {
     "duration": 0.54208,
     "end_time": "2021-07-05T13:00:52.880999",
     "exception": false,
     "start_time": "2021-07-05T13:00:52.338919",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     PassengerId  Survived\n",
      "0            892         0\n",
      "1            893         0\n",
      "2            894         1\n",
      "3            895         0\n",
      "4            896         0\n",
      "..           ...       ...\n",
      "413         1305         0\n",
      "414         1306         1\n",
      "415         1307         0\n",
      "416         1308         0\n",
      "417         1309         0\n",
      "\n",
      "[418 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "submitdata2={'PassengerId':[],'Survived':[]}\n",
    "submitdata2['PassengerId']=test_data['PassengerId']\n",
    "예측값=model.predict(testx)\n",
    "intpredict=np.around(예측값).astype(int)\n",
    "for i,rows in test_data.iterrows():\n",
    "    submitdata2['Survived'].append(intpredict[i][0])\n",
    "submitdf2=pd.DataFrame(submitdata2)\n",
    "submitdf2.to_csv(\"/kaggle/working/Submitdf.csv\",mode='w',index=False)\n",
    "print(submitdf2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 46.02887,
   "end_time": "2021-07-05T13:00:54.849708",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-07-05T13:00:08.820838",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
